{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#https://realpython.com/python-web-scraping-practical-introduction/\n",
    "\n",
    "#One useful package for web scraping that you can find in Python’s standard library is urllib\n",
    "#, which contains tools for working with URLs. \n",
    "#In particular, the urllib.request module contains a function called urlopen() that can be used to open a URL within a program.\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/aphrodite\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "\n",
    "html_bytes = page.read()\n",
    "html = html_bytes.decode(\"utf-8\")\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Aphrodite'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract Text From HTML With String Methods\n",
    "\n",
    "title_index = html.find(\"<title>\")\n",
    "title_index\n",
    "\n",
    "start_index = title_index + len(\"<title>\")\n",
    "start_index\n",
    "\n",
    "end_index = html.find(\"</title>\")\n",
    "end_index\n",
    "\n",
    "title = html[start_index:end_index]\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<head>\\n<title >Profile: Poseidon'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> url = \"http://olympus.realpython.org/profiles/poseidon\"\n",
    ">>> page = urlopen(url)\n",
    ">>> html = page.read().decode(\"utf-8\")\n",
    ">>> start_index = html.find(\"<title>\") + len(\"<title>\")\n",
    ">>> end_index = html.find(\"</title>\")\n",
    ">>> title = html[start_index:end_index]\n",
    ">>> title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x1a33fc58898>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_bytes = page.read()\n",
    "html = html_bytes.decode(\"utf-8\")\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Primer on Regular Expressions\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ac']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"ab*c\", \"ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> re.findall(\"ab*c\", \"abcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"ab*c\", \"ABC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IGNORECASE\n",
    "\n",
    "re.findall(\"ab*c\", \"ABC\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can use a period (.) to stand for any single character in a regular expression. \n",
    "\n",
    "re.findall(\"a.c\", \"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"a.c\", \"abbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The pattern .* inside a regular expression stands for any character repeated any number of times.\n",
    "re.findall(\"a.*c\", \"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Everything is ELEPHANTS.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There’s one more function in the re module that’s useful for parsing out text. re.sub(), which is short for substitute\n",
    "#, allows you to replace text in a string that matches a regular expression with new text.\n",
    "\n",
    ">>> string = \"Everything is <replaced> if it's in <tags>.\"\n",
    ">>> string = re.sub(\"<.*>\", \"ELEPHANTS\", string)\n",
    ">>> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Everything is ELEPHANTS if it's in ELEPHANTS.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"<.*?>\"\n",
    "\n",
    ">>> string = \"Everything is <replaced> if it's in <tags>.\"\n",
    ">>> string = re.sub(\"<.*?>\", \"ELEPHANTS\", string)\n",
    ">>> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: Dionysus\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "\n",
    "pattern = \"<title.*?>.*?</title.*?>\"\n",
    "match_results = re.search(pattern, html, re.IGNORECASE)\n",
    "title = match_results.group()\n",
    "title = re.sub(\"<.*?>\", \"\", title) # Remove HTML tags\n",
    "\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n<TITLE >Profile: Dionysus</title  / >\\n</head>\\n<body bgcolor=\"yellow\">\\n<center>\\n<br><br>\\n<img src=\"/static/dionysus.jpg\" />\\n<h2>Name: Dionysus</h2>\\n<img src=\"/static/grapes.png\"><br><br>\\nHometown: Mount Olympus\\n<br><br>\\nFavorite animal: Leopard <br>\\n<br>\\nFavorite Color: Wine\\n</center>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<TITLE >Profile: Dionysus</title  / >\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/dionysus.jpg\" />\n",
      "<h2>Name: Dionysus</h2>\n",
      "<img src=\"/static/grapes.png\"><br><br>\n",
      "Hometown: Mount Olympus\n",
      "<br><br>\n",
      "Favorite animal: Leopard <br>\n",
      "<br>\n",
      "Favorite Color: Wine\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "\n",
    "html_bytes = page.read()\n",
    "html = html_bytes.decode(\"utf-8\")\n",
    "\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dionysus\n"
     ]
    }
   ],
   "source": [
    "pattern = \"<h2.*?>.*?</h2.*?>\"\n",
    "match_results = re.search(pattern, html, re.IGNORECASE)\n",
    "\n",
    "title = match_results.group()\n",
    "title = re.sub(\"<.*?>\", \"\", title) # Remove HTML tags\n",
    "title = re.sub(\"Name: \", \"\", title) # Remove HTML tags\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dionysus\n",
      "Wine\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "html_page = urlopen(url)\n",
    "html_text = html_page.read().decode(\"utf-8\")\n",
    "\n",
    "\n",
    "for string in [\"Name: \", \"Favorite Color:\"]:\n",
    "    string_start_idx = html_text.find(string)\n",
    "    text_start_idx = string_start_idx + len(string)\n",
    "\n",
    "    next_html_tag_offset = html_text[text_start_idx:].find(\"<\")\n",
    "    text_end_idx = text_start_idx + next_html_tag_offset\n",
    "\n",
    "    raw_text = html_text[text_start_idx : text_end_idx]\n",
    "    clean_text = raw_text.strip(\" \\r\\n\\t\")\n",
    "    print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bill\\anaconda3\\lib\\site-packages (4.8.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\bill\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-59-c96c7464fe3c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-59-c96c7464fe3c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    pip show beautifulsoup4\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Run pip show to see the details of the package you just installed:\n",
    "pip show beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profile: Dionysus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Dionysus\n",
      "\n",
      "Hometown: Mount Olympus\n",
      "\n",
      "Favorite animal: Leopard \n",
      "\n",
      "Favorite Color: Wine\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1, image2 = soup.find_all(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/static/dionysus.jpg'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/static/grapes.png'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Profile: Dionysus</title>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful Soup automatically cleans up the tags for you by removing the extra space\n",
    "#in the opening tag and the extraneous forward slash (/) in the closing tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Dionysus'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can also retrieve just the string between the title tags with the .string property of the Tag object:\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"/static/dionysus.jpg\"/>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One of the more useful features of Beautiful Soup is the ability to search for specific kinds of tags whose attributes match certain values.\n",
    "soup.find_all(\"img\", src=\"/static/dionysus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifulSoup is great for scraping data from a website’s HTML, but it doesn’t provide any way to work with HTML forms. For example, if you need to search a website for some query and then scrape the results, then BeautifulSoup alone won’t get you very far.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://olympus.realpython.org/profiles/aphrodite\n",
      "http://olympus.realpython.org/profiles/poseidon\n",
      "http://olympus.realpython.org/profiles/dionysus\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "base_url = \"http://olympus.realpython.org\"\n",
    "\n",
    "html_page = urlopen(base_url + \"/profiles\")\n",
    "html_text = html_page.read().decode(\"utf-8\")\n",
    "\n",
    "soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "\n",
    "for link in soup.find_all(\"a\"):\n",
    "    link_url = base_url + link[\"href\"]\n",
    "    print(link_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
